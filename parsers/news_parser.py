from .base_parser import BaseParser
from bs4 import BeautifulSoup
import logging
import re

logger = logging.getLogger(__name__)


class NewsParser(BaseParser):
    """–ü–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ä–∞–∑–Ω—ã—Ö —Å–∞–π—Ç–æ–≤"""
    
    async def parse_business_news(self):
        """–ü–∞—Ä—Å–∏—Ç—å –±–∏–∑–Ω–µ—Å-–Ω–æ–≤–æ—Å—Ç–∏ —Å rbc.ru"""
        cache_key = "news_business"
        cached = self.get_cached(cache_key)
        if cached:
            return cached
        
        urls = [
            "https://www.rbc.ru/business/",
            "https://www.rbc.ru/finances/",
            "https://www.kommersant.ru/rubric/3"
        ]
        
        news_items = []
        
        for url in urls:
            html = await self.fetch_html(url)
            if not html:
                continue
                
            try:
                soup = BeautifulSoup(html, 'html.parser')
                
                if 'rbc.ru' in url:
                    # –ü–∞—Ä—Å–∏–Ω–≥ RBC
                    for item in soup.select('.news-feed__item, .item, .news-item')[:10]:
                        title_elem = item.select_one('.news-feed__item__title, .item__title, .news-item__title')
                        link_elem = item.select_one('a')
                        
                        if title_elem and link_elem:
                            title = title_elem.get_text(strip=True)
                            link = link_elem.get('href', '')
                            
                            if not link.startswith('http'):
                                link = f"https://www.rbc.ru{link}"
                            
                            if len(title) > 20:
                                news_items.append({
                                    'title': title[:200],
                                    'link': link,
                                    'source': 'RBC'
                                })
                
                elif 'kommersant.ru' in url:
                    # –ü–∞—Ä—Å–∏–Ω–≥ –ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç—ä
                    for item in soup.select('.uho__link, .rubric_lenta__item')[:10]:
                        title = item.get_text(strip=True)
                        link = item.get('href', '')
                        
                        if link and not link.startswith('http'):
                            link = f"https://www.kommersant.ru{link}"
                        
                        if len(title) > 20:
                            news_items.append({
                                'title': title[:200],
                                'link': link,
                                'source': '–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç—ä'
                            })
                
                if len(news_items) >= 5:
                    break
                    
            except Exception as e:
                logger.error(f"Error parsing {url}: {e}")
                continue
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_news = []
        seen_titles = set()
        for item in news_items:
            if item['title'] not in seen_titles:
                seen_titles.add(item['title'])
                unique_news.append(item)
        
        if not unique_news:
            unique_news = self._get_fallback_news()
        
        self.set_cache(cache_key, unique_news[:5])
        return unique_news[:5]
    
    async def parse_general_news(self):
        """–û–±—â–∏–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        return await self.parse_business_news()
    
    def _get_fallback_news(self):
        """Fallback –Ω–æ–≤–æ—Å—Ç–∏"""
        return [
            {
                'title': 'üìà –†—ã–Ω–∫–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —É–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç',
                'link': '#',
                'source': '–ê–Ω–∞–ª–∏—Ç–∏–∫–∞'
            },
            {
                'title': 'üíº –ù–æ–≤—ã–µ –º–µ—Ä—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –±–∏–∑–Ω–µ—Å–∞',
                'link': '#',
                'source': '–ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ'
            },
            {
                'title': 'üí∞ –ö—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å',
                'link': '#',
                'source': '–¶–ë –†–§'
            },
            {
                'title': 'üè¢ –ö–æ–º–ø–∞–Ω–∏–∏ –≤–Ω–µ–¥—Ä—è—é—Ç —É–¥–∞–ª–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç',
                'link': '#',
                'source': 'HR-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞'
            },
            {
                'title': 'üåç –ú–∏—Ä–æ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–∏',
                'link': '#',
                'source': 'Forbes'
            }
        ]